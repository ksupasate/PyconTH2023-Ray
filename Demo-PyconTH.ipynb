{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6ba123-063c-44ab-9521-fc0c5da212d9",
   "metadata": {},
   "source": [
    "# Session Demo\n",
    "##### Supercharging Machine Learning Tasks with Ray: An Open-Source Unified Compute Framework\n",
    "\n",
    "\n",
    "Creation by: Supasate Vorathammathorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374e335-be79-4008-bf1e-bc7d0af82e10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1501ec2a-930a-4ec0-9ea7-9a5f6f89193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 15 16:11:32 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   32C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b211882c-039a-42c5-821b-5196315a605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.15.0 in /opt/conda/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.21.12)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.54.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0.post200)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: ray in /opt/conda/lib/python3.10/site-packages (2.8.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray) (4.17.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray) (1.0.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray) (4.21.12)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray) (1.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from ray) (1.26.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (2023.7.22)\n",
      "Collecting qiskit\n",
      "  Downloading qiskit-0.45.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting qiskit-terra==0.45.1 (from qiskit)\n",
      "  Downloading qiskit_terra-0.45.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting rustworkx>=0.13.0 (from qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading rustworkx-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.17 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (1.26.0)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (3.11)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (5.9.5)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (1.11.3)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (1.12)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (0.3.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (2.8.2)\n",
      "Collecting stevedore>=3.0.0 (from qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading stevedore-5.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting symengine!=0.10.0,>=0.9 (from qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit-terra==0.45.1->qiskit) (1.16.0)\n",
      "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=3.0.0->qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading pbr-6.0.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit-terra==0.45.1->qiskit) (1.3.0)\n",
      "Downloading qiskit-0.45.1-py3-none-any.whl (9.6 kB)\n",
      "Downloading qiskit_terra-0.45.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading rustworkx-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stevedore-5.1.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (39.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pbr-6.0.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, stevedore, qiskit-terra, qiskit\n",
      "Successfully installed pbr-6.0.0 qiskit-0.45.1 qiskit-terra-0.45.1 rustworkx-0.13.2 stevedore-5.1.0 symengine-0.11.0\n",
      "Collecting qiskit-machine-learning\n",
      "  Downloading qiskit_machine_learning-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: qiskit>=0.44 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.45.1)\n",
      "Collecting qiskit-algorithms>=0.2.0 (from qiskit-machine-learning)\n",
      "  Downloading qiskit_algorithms-0.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: scipy>=1.4 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.11.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.26.0)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (5.9.5)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (1.3.2)\n",
      "Collecting fastdtw (from qiskit-machine-learning)\n",
      "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (68.2.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning) (0.3.7)\n",
      "Requirement already satisfied: qiskit-terra==0.45.1 in /opt/conda/lib/python3.10/site-packages (from qiskit>=0.44->qiskit-machine-learning) (0.45.1)\n",
      "Requirement already satisfied: rustworkx>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (0.13.2)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (3.11)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (2.8.2)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (5.1.0)\n",
      "Requirement already satisfied: symengine!=0.10.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (4.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (1.16.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (6.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit-terra==0.45.1->qiskit>=0.44->qiskit-machine-learning) (1.3.0)\n",
      "Downloading qiskit_machine_learning-0.7.1-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading qiskit_algorithms-0.2.1-py3-none-any.whl (306 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.9/306.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fastdtw\n",
      "  Building wheel for fastdtw (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastdtw: filename=fastdtw-0.3.4-py3-none-any.whl size=3566 sha256=a1fce5e41592643803a50bd27dc5f98b2fd5d0e76c541f40f0736fc0011dbf61\n",
      "  Stored in directory: /home/sagemaker-user/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
      "Successfully built fastdtw\n",
      "Installing collected packages: fastdtw, qiskit-algorithms, qiskit-machine-learning\n",
      "Successfully installed fastdtw-0.3.4 qiskit-algorithms-0.2.1 qiskit-machine-learning-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.15.0\n",
    "!pip install torch\n",
    "!pip install ray\n",
    "!pip install qiskit\n",
    "!pip install qiskit-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c68192-1f0b-47a6-b404-82043ba269ae",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9fbba2-ac1f-4032-b487-c71008a2f475",
   "metadata": {},
   "source": [
    "#### Traditional Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d56d52cd-17ac-4233-8750-c40464823e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2613 - accuracy: 0.9258\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1138 - accuracy: 0.9666\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0777 - accuracy: 0.9775\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0586 - accuracy: 0.9822\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0451 - accuracy: 0.9859\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0362 - accuracy: 0.9890\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0276 - accuracy: 0.9914\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0232 - accuracy: 0.9930\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0189 - accuracy: 0.9942\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0148 - accuracy: 0.9955\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0133 - accuracy: 0.9959\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0127 - accuracy: 0.9960\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0098 - accuracy: 0.9970\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0055 - accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 0.9984\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9988\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 6.3998e-04 - accuracy: 0.9998\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 8.3477e-04 - accuracy: 0.9997\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 5.3703e-04 - accuracy: 0.9998\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.3306e-04 - accuracy: 0.9999\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 7.9779e-04 - accuracy: 0.9997\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.9800\n",
      "\n",
      "Traditional Sequential Results: [0.2395213097333908, 0.9800000190734863]\n",
      "Time taken: 317.61598777770996 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "# Force TensorFlow to use only the CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "# Define a simple neural network model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Traditional sequential training and Timer\n",
    "start_time = time.time()\n",
    "\n",
    "model = create_model()\n",
    "model.fit(x_train, y_train, epochs=100)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\nTraditional Sequential Results:\", results)\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8e142-af39-4ac0-b80a-78512f792630",
   "metadata": {},
   "source": [
    "#### Parallel Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7882cbdf-d0fd-419b-b7d1-02427c471fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 18:37:30.883292: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-15 18:37:30.886640: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-15 18:37:30.929674: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-15 18:37:30.929712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-15 18:37:30.930825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-15 18:37:30.937462: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-15 18:37:30.937932: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-15 18:37:31.810118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 18:37:34.405003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:34.405547: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.323480: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.323994: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.396764: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.397334: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.460239: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.460776: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "2023-12-15 18:37:35.525499: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.526118: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.589202: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.589792: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.654495: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.655091: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.718422: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.718978: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "2023-12-15 18:37:35.798436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.798943: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.864478: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.865046: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:35.924901: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:35.925434: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:36.014410: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:36.015254: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "2023-12-15 18:37:36.084297: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:36.085035: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:36.171815: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:36.172823: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:36.246370: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:36.247192: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "2023-12-15 18:37:36.330911: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:36.332882: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 18:37:36.387168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 18:37:36.389192: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.9362\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4102 - accuracy: 0.9357\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3931 - accuracy: 0.9401\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4132 - accuracy: 0.9359\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4353 - accuracy: 0.9387\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3777 - accuracy: 0.9396\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4780 - accuracy: 0.9314\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4098 - accuracy: 0.9378\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3238 - accuracy: 0.9471\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4099 - accuracy: 0.9398\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.9367\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.9416\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4585 - accuracy: 0.9317\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4365 - accuracy: 0.9361\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.9384\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4872 - accuracy: 0.9306\n",
      "\n",
      "Parallel Computing Results: [[0.3777349293231964, 0.9395999908447266], [0.47800907492637634, 0.9314000010490417], [0.40980035066604614, 0.9377999901771545], [0.3238486349582672, 0.9470999836921692], [0.4099157154560089, 0.9398000240325928], [0.40331515669822693, 0.9366999864578247], [0.449887752532959, 0.9362000226974487], [0.43649110198020935, 0.9361000061035156], [0.3985280394554138, 0.9416000247001648], [0.4585290551185608, 0.9316999912261963], [0.43525072932243347, 0.9387000203132629], [0.39306217432022095, 0.9401000142097473], [0.41321054100990295, 0.9358999729156494], [0.38110873103141785, 0.9383999705314636], [0.41022977232933044, 0.935699999332428], [0.48716068267822266, 0.9305999875068665]]\n",
      "Time taken: 87.71605038642883 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "# Define a simple neural network model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define training config\n",
    "def train_model(data):\n",
    "    (x_subset, y_subset), model = data\n",
    "    model.fit(x_subset, y_subset, epochs=100, verbose=False)\n",
    "    return model.evaluate(x_test, y_test)\n",
    "\n",
    "# Parallel Computing and Timer\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "data_chunks = (np.array_split(x_train, num_processors), np.array_split(y_train, num_processors))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "processes=num_processors\n",
    "pool = multiprocessing.Pool(processes=num_processors)\n",
    "print(processes)\n",
    "results = pool.map(train_model, [(d, create_model()) for d in zip(*data_chunks)])\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\nParallel Computing Results:\", results)\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b82d96-0d99-4343-b654-d58f4b03f3ba",
   "metadata": {},
   "source": [
    "#### Distributed Computing with Ray Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684aa173-57ef-415a-b687-22a5906f43e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 18:39:29,574\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 8326299648 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-12-15 18:39:29,718\tINFO worker.py:1673 -- Started a local Ray instance.\n",
      "2023-12-15 18:39:31,285\tWARNING worker.py:2074 -- Warning: The actor MNISTModel is very large (60 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "\u001b[36m(pid=10580)\u001b[0m 2023-12-15 18:39:33.328098: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=10580)\u001b[0m 2023-12-15 18:39:33.328138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=10580)\u001b[0m 2023-12-15 18:39:33.329503: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=10580)\u001b[0m 2023-12-15 18:39:34.723280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(MNISTModel pid=10580)\u001b[0m 2023-12-15 18:39:37.285550: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[36m(MNISTModel pid=10580)\u001b[0m 2023-12-15 18:39:37.285860: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 470.57.2 does not match DSO version 520.61.5 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 [..............................] - ETA: 5:30 - loss: 0.2782 - accuracy: 0.9688\n",
      " 24/313 [=>............................] - ETA: 1s - loss: 0.3620 - accuracy: 0.9388\n",
      " 46/313 [===>..........................] - ETA: 1s - loss: 0.3958 - accuracy: 0.9266\n",
      " 67/313 [=====>........................] - ETA: 1s - loss: 0.4991 - accuracy: 0.9160\n",
      " 86/313 [=======>......................] - ETA: 1s - loss: 0.4856 - accuracy: 0.9186\n",
      "104/313 [========>.....................] - ETA: 1s - loss: 0.4641 - accuracy: 0.9225\n",
      "127/313 [===========>..................] - ETA: 0s - loss: 0.4928 - accuracy: 0.9225\n",
      " 14/313 [>.............................] - ETA: 1s - loss: 0.2379 - accuracy: 0.9509  \n",
      "144/313 [============>.................] - ETA: 0s - loss: 0.5103 - accuracy: 0.9212\n",
      " 33/313 [==>...........................] - ETA: 1s - loss: 0.3372 - accuracy: 0.9375\n",
      "166/313 [==============>...............] - ETA: 0s - loss: 0.4842 - accuracy: 0.9234\n",
      " 17/313 [>.............................] - ETA: 2s - loss: 0.2869 - accuracy: 0.9430\n",
      " 62/313 [====>.........................] - ETA: 1s - loss: 0.4755 - accuracy: 0.9224\n",
      "193/313 [=================>............] - ETA: 0s - loss: 0.4657 - accuracy: 0.9273\n",
      " 94/313 [========>.....................] - ETA: 0s - loss: 0.5049 - accuracy: 0.9232\n",
      "221/313 [====================>.........] - ETA: 0s - loss: 0.4358 - accuracy: 0.9307\n",
      "122/313 [==========>...................] - ETA: 0s - loss: 0.4942 - accuracy: 0.9249\n",
      "137/313 [============>.................] - ETA: 0s - loss: 0.5089 - accuracy: 0.9238\n",
      "252/313 [=======================>......] - ETA: 0s - loss: 0.4025 - accuracy: 0.9346\n",
      "170/313 [===============>..............] - ETA: 0s - loss: 0.4758 - accuracy: 0.9292\n",
      "  8/313 [..............................] - ETA: 2s - loss: 0.3087 - accuracy: 0.9492  \n",
      "289/313 [==========================>...] - ETA: 0s - loss: 0.3784 - accuracy: 0.9379\n",
      "200/313 [==================>...........] - ETA: 0s - loss: 0.4678 - accuracy: 0.9317\n",
      " 23/313 [=>............................] - ETA: 2s - loss: 0.4251 - accuracy: 0.9402\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.3923 - accuracy: 0.9367\n",
      "222/313 [====================>.........] - ETA: 0s - loss: 0.4525 - accuracy: 0.9334\n",
      " 38/313 [==>...........................] - ETA: 2s - loss: 0.4381 - accuracy: 0.9350\n",
      "150/313 [=============>................] - ETA: 0s - loss: 0.4793 - accuracy: 0.9273\n",
      "248/313 [======================>.......] - ETA: 0s - loss: 0.4217 - accuracy: 0.9372\n",
      " 63/313 [=====>........................] - ETA: 1s - loss: 0.5520 - accuracy: 0.9162\n",
      " 26/313 [=>............................] - ETA: 1s - loss: 0.4553 - accuracy: 0.9339\n",
      "179/313 [================>.............] - ETA: 0s - loss: 0.4415 - accuracy: 0.9324\n",
      " 48/313 [===>..........................] - ETA: 0s - loss: 0.6120 - accuracy: 0.9036\n",
      "269/313 [========================>.....] - ETA: 0s - loss: 0.4042 - accuracy: 0.9394\n",
      "104/313 [========>.....................] - ETA: 0s - loss: 0.4967 - accuracy: 0.9171\n",
      " 37/313 [==>...........................] - ETA: 1s - loss: 0.4208 - accuracy: 0.9282\n",
      " 26/313 [=>............................] - ETA: 1s - loss: 0.4335 - accuracy: 0.9327\n",
      " 59/313 [====>.........................] - ETA: 0s - loss: 0.5347 - accuracy: 0.9153\n",
      "215/313 [===================>..........] - ETA: 0s - loss: 0.4285 - accuracy: 0.9346\n",
      " 82/313 [======>.......................] - ETA: 0s - loss: 0.6268 - accuracy: 0.9051\n",
      "297/313 [===========================>..] - ETA: 0s - loss: 0.3832 - accuracy: 0.9429\n",
      "141/313 [============>.................] - ETA: 0s - loss: 0.5292 - accuracy: 0.9182\n",
      " 96/313 [========>.....................] - ETA: 0s - loss: 0.5948 - accuracy: 0.9079\n",
      " 75/313 [======>.......................] - ETA: 0s - loss: 0.6120 - accuracy: 0.9092\n",
      "232/313 [=====================>........] - ETA: 0s - loss: 0.4098 - accuracy: 0.9371\n",
      "150/313 [=============>................] - ETA: 0s - loss: 0.5054 - accuracy: 0.9183\n",
      "110/313 [=========>....................] - ETA: 0s - loss: 0.5529 - accuracy: 0.9125\n",
      "267/313 [========================>.....] - ETA: 0s - loss: 0.3890 - accuracy: 0.9401\n",
      " 34/313 [==>...........................] - ETA: 1s - loss: 0.4075 - accuracy: 0.9375\n",
      " 84/313 [=======>......................] - ETA: 0s - loss: 0.6455 - accuracy: 0.9077\n",
      "171/313 [===============>..............] - ETA: 0s - loss: 0.5004 - accuracy: 0.9225\n",
      "159/313 [==============>...............] - ETA: 0s - loss: 0.5880 - accuracy: 0.9088\n",
      " 39/313 [==>...........................] - ETA: 0s - loss: 0.4585 - accuracy: 0.9191\n",
      "185/313 [================>.............] - ETA: 0s - loss: 0.5547 - accuracy: 0.9155\n",
      " 74/313 [======>.......................] - ETA: 1s - loss: 0.5641 - accuracy: 0.9210\n",
      "137/313 [============>.................] - ETA: 0s - loss: 0.6396 - accuracy: 0.9049\n",
      "240/313 [======================>.......] - ETA: 0s - loss: 0.4404 - accuracy: 0.9298\n",
      " 17/313 [>.............................] - ETA: 0s - loss: 0.3377 - accuracy: 0.9357  \n",
      " 53/313 [====>.........................] - ETA: 0s - loss: 0.4792 - accuracy: 0.9192\n",
      " 91/313 [=======>......................] - ETA: 1s - loss: 0.5171 - accuracy: 0.9224\n",
      "216/313 [===================>..........] - ETA: 0s - loss: 0.5497 - accuracy: 0.9190\n",
      "125/313 [==========>...................] - ETA: 0s - loss: 0.5179 - accuracy: 0.9200\n",
      "291/313 [==========================>...] - ETA: 0s - loss: 0.3864 - accuracy: 0.9374\n",
      "200/313 [==================>...........] - ETA: 0s - loss: 0.4870 - accuracy: 0.9272\n",
      "281/313 [=========================>....] - ETA: 0s - loss: 0.4081 - accuracy: 0.9355\n",
      "133/313 [===========>..................] - ETA: 0s - loss: 0.6260 - accuracy: 0.9149\n",
      "248/313 [======================>.......] - ETA: 0s - loss: 0.4416 - accuracy: 0.9333\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.4165 - accuracy: 0.9347\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4695 - accuracy: 0.9305\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.9307\n",
      "273/313 [=========================>....] - ETA: 0s - loss: 0.4760 - accuracy: 0.9280\n",
      "295/313 [===========================>..] - ETA: 0s - loss: 0.4061 - accuracy: 0.9390\n",
      "212/313 [===================>..........] - ETA: 0s - loss: 0.4609 - accuracy: 0.9272\n",
      "189/313 [=================>............] - ETA: 0s - loss: 0.4587 - accuracy: 0.9314\n",
      "232/313 [=====================>........] - ETA: 0s - loss: 0.5288 - accuracy: 0.9297\n",
      " 25/313 [=>............................] - ETA: 0s - loss: 0.3638 - accuracy: 0.9400      \n",
      "257/313 [=======================>......] - ETA: 0s - loss: 0.4247 - accuracy: 0.9362\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4179 - accuracy: 0.9380\n",
      "271/313 [========================>.....] - ETA: 0s - loss: 0.4024 - accuracy: 0.9358\n",
      "250/313 [======================>.......] - ETA: 0s - loss: 0.3957 - accuracy: 0.9392\n",
      "293/313 [===========================>..] - ETA: 0s - loss: 0.4772 - accuracy: 0.9369\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4112 - accuracy: 0.9382\n",
      " 85/313 [=======>......................] - ETA: 0s - loss: 0.5432 - accuracy: 0.9158\n",
      "114/313 [=========>....................] - ETA: 0s - loss: 0.4554 - accuracy: 0.9238\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4261 - accuracy: 0.9377\n",
      "187/313 [================>.............] - ETA: 0s - loss: 0.4515 - accuracy: 0.9271\n",
      "154/313 [=============>................] - ETA: 0s - loss: 0.5434 - accuracy: 0.9184\n",
      "268/313 [========================>.....] - ETA: 0s - loss: 0.4038 - accuracy: 0.9367\n",
      "236/313 [=====================>........] - ETA: 0s - loss: 0.4615 - accuracy: 0.9313\n",
      "  1/313 [..............................] - ETA: 2:02 - loss: 0.0411 - accuracy: 1.0000\u001b[32m [repeated 6x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      " 50/313 [===>..........................] - ETA: 1s - loss: 0.4801 - accuracy: 0.9281\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 72/313 [=====>........................] - ETA: 0s - loss: 0.5625 - accuracy: 0.9128\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 88/313 [=======>......................] - ETA: 0s - loss: 0.6351 - accuracy: 0.9123\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "103/313 [========>.....................] - ETA: 0s - loss: 0.6250 - accuracy: 0.9072\n",
      "131/313 [===========>..................] - ETA: 0s - loss: 0.5387 - accuracy: 0.9215\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 13/313 [>.............................] - ETA: 1s - loss: 0.2937 - accuracy: 0.9495  \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 41/313 [==>...........................] - ETA: 1s - loss: 0.4570 - accuracy: 0.9223\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 61/313 [====>.........................] - ETA: 0s - loss: 0.5940 - accuracy: 0.9114\n",
      " 97/313 [========>.....................] - ETA: 0s - loss: 0.5172 - accuracy: 0.9217\n",
      "222/313 [====================>.........] - ETA: 0s - loss: 0.5208 - accuracy: 0.9215\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/313 [==========>...................] - ETA: 0s - loss: 0.5896 - accuracy: 0.9080\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "251/313 [=======================>......] - ETA: 0s - loss: 0.4914 - accuracy: 0.9265\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "172/313 [===============>..............] - ETA: 0s - loss: 0.5106 - accuracy: 0.9217\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "208/313 [==================>...........] - ETA: 0s - loss: 0.5602 - accuracy: 0.9171\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.9376\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "148/313 [=============>................] - ETA: 0s - loss: 0.5785 - accuracy: 0.9109\n",
      " 70/313 [=====>........................] - ETA: 0s - loss: 0.5453 - accuracy: 0.9196\n",
      " 22/313 [=>............................] - ETA: 1s - loss: 0.3969 - accuracy: 0.9332\n",
      "181/313 [================>.............] - ETA: 0s - loss: 0.5803 - accuracy: 0.9147\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 48/313 [===>..........................] - ETA: 0s - loss: 0.4784 - accuracy: 0.9251\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "210/313 [===================>..........] - ETA: 0s - loss: 0.4835 - accuracy: 0.9249\n",
      "294/313 [===========================>..] - ETA: 0s - loss: 0.3665 - accuracy: 0.9441\n",
      "262/313 [========================>.....] - ETA: 0s - loss: 0.4764 - accuracy: 0.9275\n",
      " 90/313 [=======>......................] - ETA: 0s - loss: 0.5035 - accuracy: 0.9226\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "162/313 [==============>...............] - ETA: 0s - loss: 0.5025 - accuracy: 0.9196\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 82/313 [======>.......................] - ETA: 0s - loss: 0.4999 - accuracy: 0.9196\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 12/313 [>.............................] - ETA: 1s - loss: 0.4007 - accuracy: 0.9401  \n",
      " 60/313 [====>.........................] - ETA: 0s - loss: 0.5968 - accuracy: 0.9130\n",
      "125/313 [==========>...................] - ETA: 0s - loss: 0.5466 - accuracy: 0.9165\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "202/313 [==================>...........] - ETA: 0s - loss: 0.4830 - accuracy: 0.9291\n",
      "135/313 [===========>..................] - ETA: 0s - loss: 0.5157 - accuracy: 0.9231\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4567 - accuracy: 0.9303\n",
      "231/313 [=====================>........] - ETA: 0s - loss: 0.4805 - accuracy: 0.9292\n",
      " 28/313 [=>............................] - ETA: 0s - loss: 0.4252 - accuracy: 0.9375  \n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.9359\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=10587)\u001b[0m 2023-12-15 18:39:34.234719: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=10587)\u001b[0m 2023-12-15 18:39:34.234773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=10587)\u001b[0m 2023-12-15 18:39:34.236395: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=10587)\u001b[0m 2023-12-15 18:39:35.660438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(MNISTModel pid=10587)\u001b[0m 2023-12-15 18:39:38.142601: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(MNISTModel pid=10587)\u001b[0m 2023-12-15 18:39:38.142940: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 470.57.2 does not match DSO version 520.61.5 -- cannot find working devices in this configuration\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Framework Results: [[0.4179271459579468, 0.9380000233650208], [0.4578479528427124, 0.9307000041007996], [0.39505597949028015, 0.9376000165939331], [0.36012786626815796, 0.9435999989509583], [0.3953828513622284, 0.9409999847412109], [0.3922625482082367, 0.9366999864578247], [0.4776998460292816, 0.9358999729156494], [0.42379653453826904, 0.9359999895095825], [0.383792906999588, 0.9423999786376953], [0.46945318579673767, 0.9304999709129333], [0.42608609795570374, 0.9376999735832214], [0.38524702191352844, 0.9398999810218811], [0.4165307581424713, 0.9347000122070312], [0.41118794679641724, 0.9381999969482422], [0.39745181798934937, 0.9359999895095825], [0.45669063925743103, 0.9302999973297119]]\n",
      "Time taken: 93.40018606185913 seconds\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "ray.init()\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "# Define a simple neural network model\n",
    "@ray.remote\n",
    "class MNISTModel:\n",
    "    def __init__(self):\n",
    "        self.model = Sequential([\n",
    "            Flatten(input_shape=(28, 28)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, x_subset, y_subset):\n",
    "        self.model.fit(x_subset, y_subset, epochs=100, verbose=False)\n",
    "        return self.model.evaluate(x_test, y_test)\n",
    "\n",
    "# Split dataset for distributed processing\n",
    "num_chunks = 16  # Adjust based on your cluster setup\n",
    "data_chunks = (np.array_split(x_train, num_chunks), np.array_split(y_train, num_chunks))\n",
    "\n",
    "# Measure the time for distributed model training\n",
    "start_time = time.time()\n",
    "\n",
    "models = [MNISTModel.remote() for _ in range(num_chunks)]\n",
    "result_ids = [models[i].train.remote(x, y) for i, (x, y) in enumerate(zip(*data_chunks))]\n",
    "results = ray.get(result_ids)\n",
    "\n",
    "end_time = time.time()\n",
    "ray.shutdown()\n",
    "\n",
    "print(\"Ray Framework Results:\", results)\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b6450-65da-4c17-a5e9-ac9d3ec9a0c5",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d409c4c2-7186-41b6-b051-a0141aca3a95",
   "metadata": {},
   "source": [
    "#### Traditional Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4572710b-31ed-4e5d-8fb6-ee0be9e526c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0985 - accuracy: 0.9667\n",
      "\n",
      "Traditional Sequential Results: [0.09852643311023712, 0.9666666388511658]\n",
      "Time taken: 1.3401374816894531 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "\n",
    "# Force TensorFlow to use only the CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# Load Iris data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One hot encoding of the target variable\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a simple neural network model for the Iris dataset\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')  # 3 output units for 3 classes of Iris\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Traditional sequential training and Timer\n",
    "start_time = time.time()\n",
    "\n",
    "model = create_model(X_train.shape[1])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=False)\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\nTraditional Sequential Results:\", results)\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db81c4-b61e-4be7-bdd3-1b590e4ccc88",
   "metadata": {},
   "source": [
    "#### Parallel Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63979ef2-916a-489f-a674-3c378984bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 20:15:54.325187: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-15 20:15:54.328588: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-15 20:15:54.371554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-15 20:15:54.371595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-15 20:15:54.372737: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-15 20:15:54.379224: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-15 20:15:54.379625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-15 20:15:55.258218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "2023-12-15 20:15:57.875358: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:57.875900: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "2023-12-15 20:15:58.587016: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.587531: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.591944: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.592456: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.597915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.598412: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.609024: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.609635: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.620519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.621165: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.631550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.632075: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.654648: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.655451: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.663620: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.664241: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.688483: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.689352: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.706395: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.707183: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.723729: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.724652: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.741442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.741977: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.760690: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.761500: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.777000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.777839: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n",
      "2023-12-15 20:15:58.812812: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.816166: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-15 20:15:58.817723: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-15 20:15:58.820920: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4738 - accuracy: 0.6333\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4099 - accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4706 - accuracy: 0.8667\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4221 - accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3225 - accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3911 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.3019 - accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4710 - accuracy: 0.7333\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3827 - accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.1015 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2519 - accuracy: 0.8667\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3782 - accuracy: 0.8667\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3523 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3147 - accuracy: 0.9667\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3464 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2665 - accuracy: 0.9000\n",
      "\n",
      "Parallel Computing Results: [[0.37819844484329224, 0.8666666746139526], [0.4738393723964691, 0.6333333253860474], [0.40992823243141174, 0.8999999761581421], [0.3147142827510834, 0.9666666388511658], [0.3522648513317108, 0.8333333134651184], [0.34637659788131714, 1.0], [0.39105910062789917, 0.8333333134651184], [0.32245832681655884, 0.8999999761581421], [0.4221167266368866, 0.699999988079071], [0.3826830983161926, 0.800000011920929], [0.47103989124298096, 0.7333333492279053], [0.47057756781578064, 0.8666666746139526], [0.25190502405166626, 0.8666666746139526], [0.2664952874183655, 0.8999999761581421], [2.1014530658721924, 0.6666666865348816], [0.30188363790512085, 0.8999999761581421]]\n",
      "Time taken: 4.35579776763916 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "\n",
    "# Load Iris data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One hot encoding of the target variable\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a simple neural network model for the Iris dataset\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')  # 3 output units for 3 classes of Iris\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(data):\n",
    "    (x_subset, y_subset), model = data\n",
    "    model.fit(x_subset, y_subset, epochs=100, verbose=False)\n",
    "    return model.evaluate(X_test, y_test)\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(num_processors)\n",
    "data_chunks = (np.array_split(X_train, num_processors), np.array_split(y_train, num_processors))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pool = multiprocessing.Pool(processes=num_processors)\n",
    "results = pool.map(train_model, [(d, create_model(X_train.shape[1])) for d in zip(*data_chunks)])\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\nParallel Computing Results:\", results)\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4787b00-3e6c-4913-84e4-e01b8997443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Distributed Computing with Ray Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34b7ace-f020-4234-b3a0-b82b224cb9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 20:44:09,913\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 8326295552 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-12-15 20:44:09,962\tINFO worker.py:1673 -- Started a local Ray instance.\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "\u001b[36m(pid=16842)\u001b[0m 2023-12-15 20:44:12.470649: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=16842)\u001b[0m 2023-12-15 20:44:12.470704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=16842)\u001b[0m 2023-12-15 20:44:12.472219: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=16840)\u001b[0m 2023-12-15 20:44:13.842558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(IrisModel pid=16842)\u001b[0m 2023-12-15 20:44:16.444724: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[36m(IrisModel pid=16842)\u001b[0m 2023-12-15 20:44:16.445028: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 470.57.2 does not match DSO version 520.61.5 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3188 - accuracy: 0.8667\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2775 - accuracy: 0.9667\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=16854)\u001b[0m 2023-12-15 20:44:12.570999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=16854)\u001b[0m 2023-12-15 20:44:12.571054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=16854)\u001b[0m 2023-12-15 20:44:12.572628: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=16839)\u001b[0m 2023-12-15 20:44:13.993326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(IrisModel pid=16853)\u001b[0m 2023-12-15 20:44:16.626308: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(IrisModel pid=16853)\u001b[0m 2023-12-15 20:44:16.626645: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 470.57.2 does not match DSO version 520.61.5 -- cannot find working devices in this configuration\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Framework Results: [[0.2775537073612213, 0.8666666746139526], [0.28768059611320496, 0.8333333134651184], [0.26196369528770447, 0.9666666388511658], [0.27752044796943665, 0.9666666388511658], [0.4339108169078827, 0.800000011920929], [0.31653356552124023, 1.0], [0.31879183650016785, 0.8666666746139526], [0.3247644603252411, 0.8666666746139526], [0.5704891681671143, 0.699999988079071], [0.29171842336654663, 0.8999999761581421], [0.2786290943622589, 0.9666666388511658], [0.24089689552783966, 0.9666666388511658], [0.1996387541294098, 0.9333333373069763], [0.2783876061439514, 0.9666666388511658], [3.035949468612671, 0.6666666865348816], [0.19806383550167084, 0.9666666388511658]]\n",
      "Time taken: 7.995192766189575 seconds\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "\n",
    "ray.init()\n",
    "\n",
    "# Load Iris data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One hot encoding of the target variable\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a simple neural network model for the Iris dataset\n",
    "@ray.remote\n",
    "class IrisModel:\n",
    "    def __init__(self, input_shape):\n",
    "        self.model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(3, activation='softmax')  # 3 output units for 3 classes of Iris\n",
    "        ])\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, x_subset, y_subset):\n",
    "        self.model.fit(x_subset, y_subset, epochs=100, verbose=False)\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "\n",
    "# Split dataset for distributed processing\n",
    "num_chunks = 16  # Adjust based on your cluster setup\n",
    "data_chunks = (np.array_split(X_train, num_chunks), np.array_split(y_train, num_chunks))\n",
    "\n",
    "# Measure time for distributed model training\n",
    "start_time = time.time()\n",
    "\n",
    "models = [IrisModel.remote(X_train.shape[1]) for _ in range(num_chunks)]\n",
    "result_ids = [models[i].train.remote(x, y) for i, (x, y) in enumerate(zip(*data_chunks))]\n",
    "results = ray.get(result_ids)\n",
    "\n",
    "end_time = time.time()\n",
    "ray.shutdown()\n",
    "\n",
    "print(\"Ray Framework Results:\", results)\n",
    "print(\"Time taken:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e6e3c-98f7-4729-afe9-eeb8609cd0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
